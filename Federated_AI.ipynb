{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOfv9DhDBxmGN7G093KIlb8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBe_-c_zaGzW","executionInfo":{"status":"ok","timestamp":1709173978001,"user_tz":300,"elapsed":30054,"user":{"displayName":"robert benjamin","userId":"12496057343112273971"}},"outputId":"005584be-00c3-487d-a207-b38e64223891"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import random\n","import cv2\n","import os\n","from imutils import paths\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras import backend as K\n","\n","#from fl_mnist_implementation_tutorial_utils import *"]},{"cell_type":"code","source":["###    For the given path, get the List of all files in the directory tree\n","def getListOfFiles(dirName):\n","    #RESIZE=224\n","    # create a list of file and sub directories\n","    # names in the given directory\n","    listOfFile = os.listdir(dirName)\n","    allFiles = list()\n","\n","    #read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n","    # Iterate over all the entries\n","    for entry in listOfFile:\n","        # Create full path\n","        fullPath = os.path.join(dirName, entry)\n","        # If entry is a directory then get the list of files in this directory\n","        if os.path.isdir(fullPath):\n","\n","            allFiles = allFiles + getListOfFiles(fullPath)\n","\n","        else:\n","            #img = read(fullPath)\n","\n","            #img = cv2.resize(img, (RESIZE,RESIZE))\n","            im_gray = cv2.imread(fullPath, cv2.IMREAD_GRAYSCALE)\n","            image = np.array(im_gray).flatten()\n","            # scale the image to [0, 1] and add to list\n","\n","            allFiles.append(image/255)\n","\n","\n","    return allFiles\n","\n","\n","benign_train = np.array(getListOfFiles('/content/drive/My Drive/Datasets/Tiles/LUSC1/TCGA.63.A5MM'))\n","malign_train = np.array(getListOfFiles('/content/drive/My Drive/Datasets/Tiles/LUAD1/TCGA.75.5146'))\n","#benign_valid = np.array(getListOfFiles('C:/DataSets/breast/validation/benign'))\n","#malign_valid = np.array(getListOfFiles('C:/DataSets/breast/validation/Malignant_validv2'))\n","\n","\n","# Print number of files for train/test datasets\n","print('There are %d total Benign Train files.' % len(benign_train))\n","print('There are %d total Malignant Train files.' % len(malign_train))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqfGZUIerfTq","executionInfo":{"status":"ok","timestamp":1709174062650,"user_tz":300,"elapsed":75426,"user":{"displayName":"robert benjamin","userId":"12496057343112273971"}},"outputId":"b1758e6d-521d-43f2-c322-4140b1e8ccab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1380 total Benign Train files.\n","There are 350 total Malignant Train files.\n"]}]},{"cell_type":"code","source":["#----Create numpy array of 'zeros' and 'ones' for labelling benign/malignant images resp.\n","benign_train_label = np.zeros(len(benign_train))\n","malign_train_label = np.ones(len(malign_train))\n","#benign_train_label = (-1)*benign_train_label2\n","\n","X_data = np.concatenate((benign_train, malign_train), axis = 0)\n","Y_data = np.concatenate((benign_train_label, malign_train_label), axis = 0)\n","#X_test = np.concatenate((benign_valid, malign_valid), axis = 0)\n","#Y_test = np.concatenate((benign_test_label, malign_test_label), axis = 0)\n","\n","s = np.arange(X_data.shape[0])\n","np.random.shuffle(s)\n","X_data = X_data[s] #Re-index\n","Y_data = Y_data[s]\n","\n","#binarize the labels\n","#lb = LabelBinarizer()\n","#label_list = lb.fit_transform(Y_data)\n","\n","#split data into training and test set\n","X_train, X_test, y_train, y_test = train_test_split(X_data,\n","                                                    Y_data,\n","                                                    test_size=0.1,\n","                                                    random_state=42)"],"metadata":{"id":"Zqp1oTYD0oGZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Federated Members (clients) as Data Shards"],"metadata":{"id":"IA6lUWFW5GcV"}},{"cell_type":"code","source":["def create_clients(image_list, label_list, num_clients=2, initial='clients'):\n","    ''' return: a dictionary with keys clients' names and value as\n","                data shards - tuple of images and label lists.\n","        args:\n","            image_list: a list of numpy arrays of training images\n","            label_list:a list of binarized labels for each image\n","            num_client: number of fedrated members (clients)\n","            initials: the clients'name prefix, e.g, clients_1\n","\n","    '''\n","\n","    #create a list of client names\n","    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n","    print(client_names)\n","    #randomize the data\n","    data = list(zip(image_list, label_list))\n","    random.shuffle(data)\n","\n","    #shard data and place at each client\n","    size = len(data)//num_clients\n","    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n","\n","    #number of clients must equal number of shards\n","    assert(len(shards) == len(client_names))\n","\n","    return {client_names[i] : shards[i] for i in range(len(client_names))}\n","\n","#create clients\n","clients = create_clients(X_train, y_train, num_clients=2, initial='client')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUmmvrJb31e8","executionInfo":{"status":"ok","timestamp":1709175511679,"user_tz":300,"elapsed":245,"user":{"displayName":"robert benjamin","userId":"12496057343112273971"}},"outputId":"324e8b12-1274-44c7-8a07-b1a03236258c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['client_1', 'client_2']\n"]}]},{"cell_type":"markdown","source":["Processing and batching clientsâ€™ and test data"],"metadata":{"id":"zYSUvdV_4-pI"}},{"cell_type":"code","source":["def batch_data(data_shard, bs=32):\n","    '''Takes in a clients data shard and create a tfds object off it\n","    args:\n","        shard: a data, label constituting a client's data shard\n","        bs:batch size\n","    return:\n","        tfds object'''\n","    #seperate shard into data and labels lists\n","    data, label = zip(*data_shard)\n","    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n","    return dataset.shuffle(len(label)).batch(bs)\n","\n","\n","#process and batch the training data for each client\n","clients_batched = dict()\n","for (client_name, data) in clients.items():\n","    clients_batched[client_name] = batch_data(data)\n","\n","#process and batch the test set\n","test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"],"metadata":{"id":"yfjxEjGf4Lg6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating the Multi Layer Perceptron (MLP) model"],"metadata":{"id":"9IFtD7wF45lk"}},{"cell_type":"code","source":["from keras.optimizers import SGD\n","class SimpleMLP:\n","    @staticmethod\n","    def build(shape, classes):\n","        model = Sequential()\n","        model.add(Dense(200, input_shape=(shape,)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Dense(200))\n","        model.add(Activation(\"relu\"))\n","        model.add(Dense(classes))\n","        model.add(Activation(\"sigmoid\"))\n","        return model\n","\n","\n","lr = 0.01\n","comms_round = 100\n","loss='sparse_categorical_crossentropy'\n","metrics = ['accuracy']\n","optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)"],"metadata":{"id":"vZMNl0HK4dPz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model Aggregation (Federated Averaging)"],"metadata":{"id":"8YR-uDCQ4zYP"}},{"cell_type":"code","source":["def weight_scalling_factor(clients_trn_data, client_name):\n","    client_names = list(clients_trn_data.keys())\n","    #get the bs\n","    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n","    #first calculate the total training data points across clinets\n","    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n","    # get the total number of data points held by a client\n","    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n","    return local_count/global_count\n","\n","\n","def scale_model_weights(weight, scalar):\n","    '''function for scaling a models weights'''\n","    weight_final = []\n","    steps = len(weight)\n","    for i in range(steps):\n","        weight_final.append(scalar * weight[i])\n","    return weight_final\n","\n","\n","\n","def sum_scaled_weights(scaled_weight_list):\n","    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n","    avg_grad = list()\n","    #get the average grad accross all client gradients\n","    for grad_list_tuple in zip(*scaled_weight_list):\n","        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n","        avg_grad.append(layer_mean)\n","\n","    return avg_grad\n","\n","\n"],"metadata":{"id":"FQAu4A8Q4reH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_model(X_test, y_test,  model, comm_round):\n","    #cce = tf.keras.losses.SparseCategoricalCrossentropy()\n","    cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    logits = model.predict(X_test, batch_size=100)\n","    #logits = (model.predict(X_test) > 0.5).astype(\"float\")\n","    #logits = model.predict(X_test)\n","    loss = cce(y_test, logits)\n","    #print(logits)\n","    #loss = cce(y_test)\n","    #acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(y_test, axis = 1))\n","    acc = accuracy_score(tf.argmax(logits, axis=1), y_test)\n","    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n","    return acc, loss"],"metadata":{"id":"v4bn50WKw_Yg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Federated Model Training\n"],"metadata":{"id":"-D7mgyM95O3j"}},{"cell_type":"code","source":["#initialize global model\n","smlp_global = SimpleMLP()\n","global_model = smlp_global.build(961, 2)\n","\n","global_acc_list = []\n","global_loss_list = []\n","\n","#commence global training loop\n","for comm_round in range(comms_round):\n","\n","    # get the global model's weights - will serve as the initial weights for all local models\n","    global_weights = global_model.get_weights()\n","\n","    #initial list to collect local model weights after scalling\n","    scaled_local_weight_list = list()\n","\n","    #randomize client data - using keys\n","    client_names= list(clients_batched.keys())\n","    random.shuffle(client_names)\n","\n","    #loop through each client and create new local model\n","    for client in client_names:\n","        smlp_local = SimpleMLP()\n","        local_model = smlp_local.build(961, 2)\n","        local_model.compile(loss=loss,\n","                      optimizer=optimizer,\n","                      metrics=metrics)\n","\n","        #set local model weight to the weight of the global model\n","        local_model.set_weights(global_weights)\n","\n","        #fit local model with client's data\n","        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n","\n","        #scale the model weights and add to list\n","        scaling_factor = weight_scalling_factor(clients_batched, client)\n","        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n","        scaled_local_weight_list.append(scaled_weights)\n","\n","        #clear session to free memory after each communication round\n","        K.clear_session()\n","\n","    #to get the average over all the local model, we simply take the sum of the scaled weights\n","    average_weights = sum_scaled_weights(scaled_local_weight_list)\n","\n","    #update global model\n","    global_model.set_weights(average_weights)\n","\n","    #test global model and print out metrics after each communications round\n","    for(X_test, y_test) in test_batched:\n","        global_acc, global_loss = test_model(X_test, y_test, global_model, comm_round)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vj4NeMXV5T1_","executionInfo":{"status":"ok","timestamp":1709180645620,"user_tz":300,"elapsed":150421,"user":{"displayName":"robert benjamin","userId":"12496057343112273971"}},"outputId":"27a88e66-d313-4d3d-d105-4dea177b8dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 9ms/step\n","comm_round: 0 | global_acc: 82.081% | global_loss: 0.6163625121116638\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 1 | global_acc: 80.925% | global_loss: 0.6353694200515747\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 2 | global_acc: 80.925% | global_loss: 0.6263630390167236\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 3 | global_acc: 80.925% | global_loss: 0.6348424553871155\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 4 | global_acc: 81.503% | global_loss: 0.6174077987670898\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 5 | global_acc: 81.503% | global_loss: 0.6229887008666992\n","2/2 [==============================] - 0s 13ms/step\n","comm_round: 6 | global_acc: 81.503% | global_loss: 0.5995201468467712\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 7 | global_acc: 81.503% | global_loss: 0.6150895357131958\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 8 | global_acc: 81.503% | global_loss: 0.6162017583847046\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 9 | global_acc: 81.503% | global_loss: 0.6043610572814941\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 10 | global_acc: 82.659% | global_loss: 0.6193488240242004\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 11 | global_acc: 83.815% | global_loss: 0.6324115991592407\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 12 | global_acc: 82.081% | global_loss: 0.600619912147522\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 13 | global_acc: 82.081% | global_loss: 0.6036138534545898\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 14 | global_acc: 83.237% | global_loss: 0.6102831363677979\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 15 | global_acc: 82.081% | global_loss: 0.6002938151359558\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 16 | global_acc: 82.081% | global_loss: 0.5946160554885864\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 17 | global_acc: 82.081% | global_loss: 0.5938251614570618\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 18 | global_acc: 82.081% | global_loss: 0.5784223079681396\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 19 | global_acc: 82.659% | global_loss: 0.5923731923103333\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 20 | global_acc: 86.705% | global_loss: 0.6142594218254089\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 21 | global_acc: 82.081% | global_loss: 0.5723313093185425\n","2/2 [==============================] - 0s 14ms/step\n","comm_round: 22 | global_acc: 82.659% | global_loss: 0.5863086581230164\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 23 | global_acc: 84.393% | global_loss: 0.5956228971481323\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 24 | global_acc: 82.659% | global_loss: 0.559908390045166\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 25 | global_acc: 83.237% | global_loss: 0.5740677714347839\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 26 | global_acc: 82.659% | global_loss: 0.5555543303489685\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 27 | global_acc: 83.815% | global_loss: 0.5753469467163086\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 28 | global_acc: 83.815% | global_loss: 0.5610889792442322\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 29 | global_acc: 84.393% | global_loss: 0.5601415038108826\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 30 | global_acc: 84.393% | global_loss: 0.557115912437439\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 31 | global_acc: 84.393% | global_loss: 0.5637120008468628\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 32 | global_acc: 84.971% | global_loss: 0.5648292303085327\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 33 | global_acc: 76.879% | global_loss: 0.6351075172424316\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 34 | global_acc: 82.659% | global_loss: 0.5376586318016052\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 35 | global_acc: 89.017% | global_loss: 0.5748026967048645\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 36 | global_acc: 89.595% | global_loss: 0.5833304524421692\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 37 | global_acc: 86.127% | global_loss: 0.5533022880554199\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 38 | global_acc: 82.659% | global_loss: 0.5282315611839294\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 39 | global_acc: 82.659% | global_loss: 0.5246666669845581\n","2/2 [==============================] - 0s 11ms/step\n","comm_round: 40 | global_acc: 87.283% | global_loss: 0.5762057304382324\n","2/2 [==============================] - 0s 11ms/step\n","comm_round: 41 | global_acc: 84.393% | global_loss: 0.5319177508354187\n","2/2 [==============================] - 0s 5ms/step\n","comm_round: 42 | global_acc: 84.393% | global_loss: 0.534613847732544\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 43 | global_acc: 83.237% | global_loss: 0.5232916474342346\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 44 | global_acc: 89.017% | global_loss: 0.5631921291351318\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 45 | global_acc: 83.237% | global_loss: 0.5138776302337646\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 46 | global_acc: 83.237% | global_loss: 0.5123921632766724\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 47 | global_acc: 89.017% | global_loss: 0.5431488752365112\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 48 | global_acc: 86.127% | global_loss: 0.5287800431251526\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 49 | global_acc: 88.439% | global_loss: 0.5492303371429443\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 50 | global_acc: 83.815% | global_loss: 0.6003932356834412\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 51 | global_acc: 84.393% | global_loss: 0.5159140825271606\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 52 | global_acc: 83.815% | global_loss: 0.5078726410865784\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 53 | global_acc: 84.971% | global_loss: 0.5151363015174866\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 54 | global_acc: 87.861% | global_loss: 0.5247859358787537\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 55 | global_acc: 86.127% | global_loss: 0.5672875642776489\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 56 | global_acc: 84.393% | global_loss: 0.507372260093689\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 57 | global_acc: 83.815% | global_loss: 0.501198947429657\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 58 | global_acc: 87.861% | global_loss: 0.5126840472221375\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 59 | global_acc: 84.971% | global_loss: 0.5032348036766052\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 60 | global_acc: 82.659% | global_loss: 0.49638330936431885\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 61 | global_acc: 84.971% | global_loss: 0.5012893080711365\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 62 | global_acc: 89.017% | global_loss: 0.5217936038970947\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 63 | global_acc: 84.393% | global_loss: 0.49890801310539246\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 64 | global_acc: 87.861% | global_loss: 0.5047837495803833\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 65 | global_acc: 84.393% | global_loss: 0.494540274143219\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 66 | global_acc: 87.283% | global_loss: 0.4984508752822876\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 67 | global_acc: 87.283% | global_loss: 0.4976857900619507\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 68 | global_acc: 85.549% | global_loss: 0.4919707775115967\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 69 | global_acc: 83.815% | global_loss: 0.4878171384334564\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 70 | global_acc: 86.705% | global_loss: 0.49103668332099915\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 71 | global_acc: 87.861% | global_loss: 0.4948395788669586\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 72 | global_acc: 88.439% | global_loss: 0.49447888135910034\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 73 | global_acc: 88.439% | global_loss: 0.5050719380378723\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 74 | global_acc: 84.971% | global_loss: 0.4848063886165619\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 75 | global_acc: 88.439% | global_loss: 0.49389609694480896\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 76 | global_acc: 87.861% | global_loss: 0.49001091718673706\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 77 | global_acc: 89.595% | global_loss: 0.5031713843345642\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 78 | global_acc: 89.017% | global_loss: 0.5051941871643066\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 79 | global_acc: 88.439% | global_loss: 0.49713200330734253\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 80 | global_acc: 89.017% | global_loss: 0.4898223876953125\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 81 | global_acc: 88.439% | global_loss: 0.4984501302242279\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 82 | global_acc: 89.017% | global_loss: 0.4941372275352478\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 83 | global_acc: 86.705% | global_loss: 0.4804646074771881\n","2/2 [==============================] - 0s 11ms/step\n","comm_round: 84 | global_acc: 89.017% | global_loss: 0.4995171129703522\n","2/2 [==============================] - 0s 10ms/step\n","comm_round: 85 | global_acc: 86.705% | global_loss: 0.4778865873813629\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 86 | global_acc: 87.861% | global_loss: 0.479474276304245\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 87 | global_acc: 87.861% | global_loss: 0.4798383414745331\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 88 | global_acc: 88.439% | global_loss: 0.4851798713207245\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 89 | global_acc: 87.861% | global_loss: 0.4769114553928375\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 90 | global_acc: 87.283% | global_loss: 0.4744730591773987\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 91 | global_acc: 87.283% | global_loss: 0.4737924635410309\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 92 | global_acc: 87.861% | global_loss: 0.47519612312316895\n","2/2 [==============================] - 0s 12ms/step\n","comm_round: 93 | global_acc: 88.439% | global_loss: 0.4752385914325714\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 94 | global_acc: 88.439% | global_loss: 0.47864192724227905\n","2/2 [==============================] - 0s 6ms/step\n","comm_round: 95 | global_acc: 88.439% | global_loss: 0.47989004850387573\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 96 | global_acc: 88.439% | global_loss: 0.4745672941207886\n","2/2 [==============================] - 0s 8ms/step\n","comm_round: 97 | global_acc: 88.439% | global_loss: 0.4754010736942291\n","2/2 [==============================] - 0s 7ms/step\n","comm_round: 98 | global_acc: 87.283% | global_loss: 0.5308787226676941\n","2/2 [==============================] - 0s 9ms/step\n","comm_round: 99 | global_acc: 88.439% | global_loss: 0.4763585925102234\n"]}]},{"cell_type":"markdown","source":["SGD Vs Federated Averaging"],"metadata":{"id":"_fKfnBDg6Jsu"}},{"cell_type":"code","source":["SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)\n","smlp_SGD = SimpleMLP()\n","SGD_model = smlp_SGD.build(784, 10)\n","\n","SGD_model.compile(loss=loss,\n","              optimizer=optimizer,\n","              metrics=metrics)\n","\n","# fit the SGD training data to model\n","_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)\n","\n","#test the SGD global model and print out metrics\n","for(X_test, Y_test) in test_batched:\n","        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)\n"],"metadata":{"id":"I3SBuSm75b1a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"fkMHpjcF6VA5"}},{"cell_type":"code","source":["def non_iid_x(image_list, label_list, x=1, num_intraclass_clients=10):\n","        ''' creates x non_IID clients\n","        args:\n","            image_list: python list of images or data points\n","            label_list: python list of labels\n","            x: none IID severity, 1 means each client will only have one class of data\n","            num_intraclass_client: number of sub-client to be created from each none IID class,\n","            e.g for x=1, we could create 10 further clients by splitting each class into 10\n","\n","        return - dictionary\n","            keys - clients's name,\n","            value - client's non iid 1 data shard (as tuple list of images and labels) '''\n","\n","        non_iid_x_clients = dict()\n","\n","        #create unique label list and shuffle\n","        unique_labels = np.unique(np.array(label_list))\n","        random.shuffle(unique_labels)\n","\n","        #create sub label lists based on x\n","        sub_lab_list = [unique_labels[i:i + x] for i in range(0, len(unique_labels), x)]\n","\n","        for item in sub_lab_list:\n","            class_data = [(image, label) for (image, label) in zip(image_list, label_list) if label in item]\n","\n","            #decouple tuple list into seperate image and label lists\n","            images, labels = zip(*class_data)\n","\n","            # create formated client initials\n","            initial = ''\n","            for lab in item:\n","                initial = initial + lab + '_'\n","\n","            #create num_intraclass_clients clients from the class\n","            intraclass_clients = create_clients(list(images), list(labels), num_intraclass_clients, initial)\n","\n","            #append intraclass clients to main clients'dict\n","            non_iid_x_clients.update(intraclass_clients)\n","\n","        return non_iid_x_clients"],"metadata":{"id":"-2m6bZ5k6VR5"},"execution_count":null,"outputs":[]}]}